{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e787d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 1) Imports & drive paths ───────────────────────────────────────────────\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import densenet121\n",
    "from pydicom import dcmread\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import zipfile, io\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "# Point at your external drive:\n",
    "DRIVE_ROOT   = \"/Volumes/Extra Storage\"\n",
    "DATA_DIR     = os.path.join(DRIVE_ROOT, \"local_ADS_data\", \"necessary_sufficient\")\n",
    "RESULTS_DIR  = os.path.join(DRIVE_ROOT, \"local_ADS_data\", \"animations\")\n",
    "WEIGHTS_PATH = os.path.join(DRIVE_ROOT, \"models\", \"reproduceable_densenet.pt\")\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "546bb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3acdb545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_as_pil(path):\n",
    "    \"\"\"\n",
    "    path can be either:\n",
    "      - \"/full/path/to/foo.dcm\"   (plain file), or\n",
    "      - \"/full/path/to/data.zip!inner/folder/foo.dcm\"\n",
    "    \"\"\"\n",
    "    if \"!\" in path:\n",
    "        archive_path, inner_path = path.split(\"!\", 1)\n",
    "        inner_path = inner_path.lstrip(\"/\")  # no leading slash in the archive\n",
    "        with zipfile.ZipFile(archive_path, \"r\") as zf:\n",
    "            data = zf.read(inner_path)\n",
    "            ds   = pydicom.dcmread(io.BytesIO(data))\n",
    "    else:\n",
    "        ds = pydicom.dcmread(path)\n",
    "\n",
    "    arr = ds.pixel_array.astype(np.float32)\n",
    "    # normalize to [0,255] so PIL can handle it nicely\n",
    "    arr = (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n",
    "    arr = (arr * 255).clip(0,255).astype(np.uint8)\n",
    "    return Image.fromarray(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0347a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MEAN = 0.5007\n",
    "TRAIN_STD  = 0.2508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8391d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda t: t.float()),\n",
    "    transforms.Normalize([TRAIN_MEAN], [TRAIN_STD])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a9877ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_mask(model, x, alpha=1.0, lr=0.5, log_every=10, tol=1e-5, max_no_improve=5, init_mask=None, output_dir=None, prefix=None):\n",
    "    \"\"\"\n",
    "    Optimize a mask with learning rate decay and safe return on interrupt.\n",
    "    \"\"\"\n",
    "    mask = torch.nn.Parameter(init_mask.clone().detach() if init_mask is not None else torch.ones_like(x), requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([mask], lr=lr)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=200, gamma=0.9)\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLRS(optimizer, gamma=0.9)\n",
    "\n",
    "    mask_history = []\n",
    "    suff_history = []\n",
    "    nec_history  = []\n",
    "    sparsity_history = []\n",
    "    tv_history = []\n",
    "    prev_loss = float('inf')\n",
    "    no_improve_count = 0\n",
    "    step = 0\n",
    "    changed_class = False\n",
    "    best_loss = float('inf')\n",
    "    best_mask = None   \n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            optimizer.zero_grad()\n",
    "            loss, components = explanation_loss(model, x, mask, background_path= \"mean_image.pt\", alpha=alpha, return_components=True)\n",
    "            \n",
    "            if components['loss'] < best_loss:\n",
    "                best_loss = components['loss']\n",
    "                best_mask = mask.detach().clone()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            mask.data.clamp_(0, 1)\n",
    "\n",
    "            if (step + 1) % log_every == 0 or step == 0:\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                print(f\"Step {step+1:4d}: \"\n",
    "                      f\"Loss={components['loss']:.6f} | \"\n",
    "                      f\"Suff={components['sufficiency']:.6f} | \"\n",
    "                      f\"Nec={components['necessity']:.6f} | \"\n",
    "                      f\"L1={components['l1']:.6f} | \"\n",
    "                      f\"TV={components['tv']:.6f} | \"\n",
    "                      f\"Changed (keep): {components['changed_with_keep']} | \"\n",
    "                      f\"Changed (remove): {components['changed_with_remove']} | \"\n",
    "                      f\"LR={current_lr:.6e}\")\n",
    "                mask_history.append(mask.detach().cpu().clone())\n",
    "                suff_history.append(components['sufficiency'])\n",
    "                nec_history.append( components['necessity'] )\n",
    "                sparsity_history.append( mask.abs().mean().item() )\n",
    "                tv_history.append(components['tv'])\n",
    "\n",
    "                if alpha == 1.0 and components['changed_with_keep']:\n",
    "                    changed_class = True\n",
    "                elif alpha == 0.0 and components['changed_with_remove']:\n",
    "                    changed_class = True\n",
    "\n",
    "            loss_delta = abs(prev_loss - components['loss'])\n",
    "            if loss_delta < tol:\n",
    "                no_improve_count += 1\n",
    "                if no_improve_count >= max_no_improve:\n",
    "                    print(f\"Converged at step {step+1} (loss change < {tol} for {max_no_improve} steps)\")\n",
    "                    break\n",
    "            else:\n",
    "                no_improve_count = 0\n",
    "\n",
    "            prev_loss = components['loss']\n",
    "            step += 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\n⏹️ Optimization manually interrupted at step {step+1}. Returning current mask.\")\n",
    "    \n",
    "    final_mask = best_mask\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(suff_history,      label='Sufficiency', linewidth=2)\n",
    "    ax.plot(nec_history,       label='Necessity',    linewidth=2)\n",
    "    ax.plot(sparsity_history,  label='Sparsity',     linewidth=2)\n",
    "    ax.plot(tv_history, label = 'Smoothness', linewidth = 2)\n",
    "\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Metric Value\")\n",
    "    ax.set_title(\"Sufficiency, Necessity & Sparsity over Optimization\")\n",
    "    ax.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if output_dir and prefix:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # 1) final mask\n",
    "        torch.save(final_mask.cpu(),\n",
    "                   os.path.join(output_dir, f\"{prefix}_final_mask.pt\"))\n",
    "        # 2) mask history\n",
    "        torch.save([m.cpu() for m in mask_history],\n",
    "                   os.path.join(output_dir, f\"{prefix}_mask_history.pt\"))\n",
    "        # 3) metric plot\n",
    "        fig.savefig(os.path.join(output_dir, f\"{prefix}_metrics.png\"))\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return mask.detach(), mask_history, changed_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "939b6aa9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DenseNet:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([1000, 1024]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([1000]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q2/5dzhb7k53d7_qcl4qdn0kbmc0000gn/T/ipykernel_30107/3316803591.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m model.load_state_dict(torch.load(\n\u001b[1;32m     26\u001b[0m     \u001b[0;34m\"/Users/Kyra_1/Downloads/reproduceable_densenet.pt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m ))\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1672\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DenseNet:\n\tsize mismatch for classifier.weight: copying a param with shape torch.Size([4, 1024]) from checkpoint, the shape in current model is torch.Size([1000, 1024]).\n\tsize mismatch for classifier.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([1000])."
     ]
    }
   ],
   "source": [
    "# ─── Load & patch a single-channel DenseNet ─────────────────────────────────\n",
    "from torchvision.models import densenet121\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1) instantiate the standard DenseNet121\n",
    "model = densenet121(pretrained=True)\n",
    "\n",
    "# 2) swap its first conv (3→1 channel)\n",
    "old_conv = model.features.conv0\n",
    "new_conv = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=old_conv.out_channels,\n",
    "    kernel_size=old_conv.kernel_size,\n",
    "    stride=old_conv.stride,\n",
    "    padding=old_conv.padding,\n",
    "    bias=(old_conv.bias is not None)\n",
    ")\n",
    "with torch.no_grad():\n",
    "    # initialize new_conv by averaging the RGB weights\n",
    "    new_conv.weight[:] = old_conv.weight.mean(dim=1, keepdim=True)\n",
    "model.features.conv0 = new_conv\n",
    "\n",
    "# 3) move to device & load your fine-tuned weights\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(\n",
    "    \"/Users/Kyra_1/Downloads/reproduceable_densenet.pt\",\n",
    "    map_location=device\n",
    "))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa934e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 2) Load your model & helper funcs ───────────────────────────────────────\n",
    "# Replace with whatever model class & loading you use\n",
    "from your_model_module import YourMaskModel, optimize_mask, load_data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model  = YourMaskModel().to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8174d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 3) Utility: load a DICOM into a normalized torch.Tensor ────────────────\n",
    "def load_dicom_tensor(dicom_id):\n",
    "    path = os.path.join(DATA_DIR, f\"{dicom_id}.dcm\")\n",
    "    ds   = dcmread(path, force=True)\n",
    "    arr  = ds.pixel_array.astype(np.float32)\n",
    "    norm = (arr - arr.min()) / (arr.ptp() + 1e-6)\n",
    "    # shape → (1, H, W)\n",
    "    return torch.from_numpy(norm).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 4) Utility: save figures & .pt ─────────────────────────────────────────\n",
    "def save_overlay(orig, mask, out_path):\n",
    "    plt.imshow(orig, cmap=\"gray\")\n",
    "    plt.imshow(mask, cmap=\"jet\", alpha=0.5)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def save_loss_history(history, out_path):\n",
    "    plt.plot(history[\"sufficiency\"], label=\"sufficiency\")\n",
    "    plt.plot(history[\"necessity\"],  label=\"necessity\")\n",
    "    plt.plot(history[\"sparsity\"],   label=\"sparsity\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c201977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 5) Single‐ID pipeline ───────────────────────────────────────────────────\n",
    "def process_dicom_id(dicom_id):\n",
    "    # 1) Load image tensor\n",
    "    x = load_dicom_tensor(dicom_id).unsqueeze(0).to(device)  # (1,1,H,W)\n",
    "    \n",
    "    # 2) Run your optimization/masking routine\n",
    "    #    should return final_mask, mask_history, model_pred\n",
    "    final_mask, mask_history, model_pred = optimize_mask(\n",
    "        model, x,\n",
    "        alpha=0.5,\n",
    "        init_mask=torch.ones_like(x),\n",
    "        output_dir=None,      # we’ll handle saving ourselves\n",
    "        prefix=None\n",
    "    )\n",
    "    \n",
    "    # 3) Prepare output paths\n",
    "    base = os.path.join(RESULTS_DIR, dicom_id)\n",
    "    os.makedirs(base, exist_ok=True)\n",
    "    mask_pt_path    = os.path.join(base, f\"{dicom_id}_final_mask.pt\")\n",
    "    overlay_png     = os.path.join(base, f\"{dicom_id}_overlay.png\")\n",
    "    losses_png      = os.path.join(base, f\"{dicom_id}_loss_history.png\")\n",
    "    pred_txt        = os.path.join(base, f\"{dicom_id}_prediction.txt\")\n",
    "    \n",
    "    # 4) Save final mask as .pt\n",
    "    torch.save(final_mask.detach().cpu(), mask_pt_path)\n",
    "    \n",
    "    # 5) Save overlay figure\n",
    "    orig = x.squeeze().cpu().numpy()\n",
    "    m    = final_mask.squeeze().cpu().numpy()\n",
    "    save_overlay(orig, m, overlay_png)\n",
    "    \n",
    "    # 6) Save loss history plot\n",
    "    save_loss_history(mask_history, losses_png)\n",
    "    \n",
    "    # 7) Save model prediction\n",
    "    with open(pred_txt, \"w\") as f:\n",
    "        f.write(f\"Predicted class: {model_pred}\\n\")\n",
    "    \n",
    "    print(f\"[✓] Done {dicom_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 6) Run on one (or many) IDs ─────────────────────────────────────────────\n",
    "# Example: single ID\n",
    "process_dicom_id(\"4c8be7b3-4bdfb53a-5291392a-e9387349-55fd937c\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
