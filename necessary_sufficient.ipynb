{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c3ea64",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "205f4183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import densenet121\n",
    "import pydicom\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3cc55ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_as_pil(path):\n",
    "    ds = pydicom.dcmread(path)\n",
    "    img = ds.pixel_array.astype(np.float32)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "    img = (img * 255).round().astype(np.uint8)\n",
    "    return Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "465b20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the train mean and std\n",
    "train_mean = 0.5037\n",
    "train_std = 0.2510\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=train_mean, std=train_std),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c0a05",
   "metadata": {},
   "source": [
    "## Import Data + Model\n",
    "\n",
    "Class 0 \n",
    "Class 1\n",
    "Class 2\n",
    "Class 3 == white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bb4e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kyra_1/Downloads/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/Kyra_1/Downloads/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 2) Settings\n",
    "device          = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint_path = \"best_densenet_ethnicity.pth\"\n",
    "num_classes     = 4     # ← change to match your len(unique_labels)\n",
    "IMG_SIZE        = 224   # ← whatever size you trained with\n",
    "\n",
    "# 3) Re-instantiate your model exactly as in training\n",
    "model = densenet121(pretrained=False)\n",
    "# – swap in a 1-channel conv0\n",
    "model.features.conv0 = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=64,\n",
    "    kernel_size=7,\n",
    "    stride=2,\n",
    "    padding=3,\n",
    "    bias=False\n",
    ")\n",
    "# – swap in your 4-way classifier\n",
    "model.classifier = nn.Linear(\n",
    "    in_features=model.classifier.in_features,\n",
    "    out_features=num_classes\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# 4) Load the weights\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# 5) Switch to eval mode\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# 7) Inference on a single image\n",
    "def predict_dicom(dicom_path):\n",
    "    # read & preprocess\n",
    "    pil_img = load_dicom_as_pil(dicom_path)\n",
    "    x       = transform(pil_img).unsqueeze(0).to(device) \n",
    "    # forward\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs  = torch.softmax(logits, dim=1)\n",
    "    pred_idx = probs.argmax(dim=1).item()\n",
    "    return pred_idx, probs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a3149a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ASIAN': 0, 'BLACK/AFRICAN AMERICAN': 1, 'HISPANIC/LATINO': 2, 'WHITE': 3}\n",
      "   patient_id                                         dicom_path  class_idx  \\\n",
      "0    15000485  /Users/Kyra_1/Desktop/local_ADS_data/physionet...          3   \n",
      "1    15000485  /Users/Kyra_1/Desktop/local_ADS_data/physionet...          3   \n",
      "2    15000485  /Users/Kyra_1/Desktop/local_ADS_data/physionet...          3   \n",
      "3    15002678  /Users/Kyra_1/Desktop/local_ADS_data/physionet...          3   \n",
      "4    15002678  /Users/Kyra_1/Desktop/local_ADS_data/physionet...          3   \n",
      "\n",
      "     prob_0    prob_1    prob_2    prob_3  \n",
      "0  0.005292  0.015935  0.001419  0.977354  \n",
      "1  0.019677  0.301652  0.007453  0.671218  \n",
      "2  0.028240  0.144241  0.011913  0.815606  \n",
      "3  0.042485  0.099779  0.017487  0.840249  \n",
      "4  0.057175  0.052740  0.151839  0.738246  \n",
      "(19, 7)\n",
      "1\n",
      "['/Users/Kyra_1/Desktop/local_ADS_data/physionet.org/files/mimic-cxr/2.1.0//files/p15/p15002678/s51171473/a57016f6-7e508b1c-2ae93482-05af10fa-6222510b.dcm']\n"
     ]
    }
   ],
   "source": [
    "# processing to go through all the available data (assuming all the available data is recorded in best_model_pred.csv)\n",
    "\n",
    "local_path_stem = \"/Users/Kyra_1/Desktop/local_ADS_data/physionet.org/files/mimic-cxr/2.1.0/\"\n",
    "\n",
    "successful_files = pd.read_csv(\"best_model_pred.csv\")\n",
    "\n",
    "all_labels = successful_files['true_label']\n",
    "# recreate the label mapping from the training\n",
    "unique_labels = sorted(all_labels.unique())\n",
    "label2idx     = {lab: i for i, lab in enumerate(unique_labels)}\n",
    "print(label2idx)\n",
    "\n",
    "og_image_predictions = []\n",
    "label_ambiguity_count = 0\n",
    "label_ambiguity_ids = []\n",
    "\n",
    "for _, row in successful_files.iterrows():\n",
    "    patient_id = row['subject_id']\n",
    "    other_path = row['dicom_path'].split('2.1.0')[1]\n",
    "    full_path  = local_path_stem+ other_path\n",
    "    train_label = row['predicted']\n",
    "    if not os.path.exists(full_path):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        idx, probs = predict_dicom(full_path)\n",
    "        if label2idx[train_label] != idx:\n",
    "            label_ambiguity_count += 1\n",
    "            label_ambiguity_ids.append(full_path)\n",
    "\n",
    "    except:\n",
    "        print(f'Skipped: {patient_id}')\n",
    "        continue\n",
    "\n",
    "    p0, p1, p2, p3 = probs.flatten().tolist()\n",
    "\n",
    "    og_image_predictions.append({\n",
    "        'patient_id': patient_id,\n",
    "        'dicom_path': full_path,\n",
    "        'class_idx':  idx,    \n",
    "        'prob_0':      p0,\n",
    "        'prob_1':      p1,\n",
    "        'prob_2':      p2,\n",
    "        'prob_3':      p3,\n",
    "    })\n",
    "\n",
    "pred_df = pd.DataFrame(og_image_predictions)\n",
    "print(pred_df.head())\n",
    "pred_df.to_csv(\"ethnicity_preds.csv\", index=False)\n",
    "print(pred_df.shape)\n",
    "print(label_ambiguity_count)\n",
    "print(label_ambiguity_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce3a0d7",
   "metadata": {},
   "source": [
    "0.09404128\t0.1083391085267067\t0.4549783170223236\t0.34264135360717773\n",
    "0.011608587577939034, 0.057486627250909805, 0.23680849373340607, 0.6940963268280029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e763e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(model.training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35503a2c",
   "metadata": {},
   "source": [
    "## Masks\n",
    "\n",
    "Can make more complicated later?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c3a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a learnable mask with different initializations to capture different solutions\n",
    "mask = torch.nn.Parameter(torch.rand(1, 1, 224, 224), requires_grad=True)\n",
    "optimizer = torch.optim.Adam([mask], lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c64c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m masks = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mN\u001b[49m):  \u001b[38;5;66;03m# N = number of explanations\u001b[39;00m\n\u001b[32m      4\u001b[39m     mask = torch.nn.Parameter(torch.rand(\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m), requires_grad=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m     optimizer = torch.optim.Adam([mask], lr=\u001b[32m1e-2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'N' is not defined"
     ]
    }
   ],
   "source": [
    "masks = []\n",
    "\n",
    "# set the number of different sets you would like\n",
    "\n",
    "for _ in range(10):  \n",
    "    mask = torch.nn.Parameter(torch.rand(1, 1, 224, 224), requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([mask], lr=1e-2)\n",
    "\n",
    "    for i in range(500):\n",
    "        masks.append(mask.detach().clone())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
