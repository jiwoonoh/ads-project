{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366a00c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121\n",
    "from torchvision import transforms\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6babf2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MEAN = 0.5007\n",
    "TRAIN_STD  = 0.2508"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69a00898",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([TRAIN_MEAN], [TRAIN_STD]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daafb3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Kyra_1/Desktop/test_data already exists, skipping unzip\n"
     ]
    }
   ],
   "source": [
    "zip_path   = \"/Users/Kyra_1/Desktop/test_data.zip\"\n",
    "extract_to = \"/Users/Kyra_1/Desktop/test_data\"\n",
    "\n",
    "# only extract if the dir doesn't already exist\n",
    "if not os.path.isdir(extract_to):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_to)\n",
    "    print(f\"Unzipped into {extract_to}\")\n",
    "else:\n",
    "    print(f\"{extract_to} already exists, skipping unzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d3e457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kyra_1/Downloads/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/Kyra_1/Downloads/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/Users/Kyra_1/Downloads/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1842: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.047058823529411764..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0012466488406062126..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.014304636046290398..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.004198950249701738..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0032270459923893213..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:659] . unexpected pos 832 vs 726",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/.venv/lib/python3.12/site-packages/torch/serialization.py:965\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/.venv/lib/python3.12/site-packages/torch/serialization.py:1266\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[39m\n\u001b[32m   1265\u001b[39m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:862] . PytorchStreamWriter failed writing file data/0: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# ---- save outputs ----\u001b[39;00m\n\u001b[32m    116\u001b[39m torch.save(torch.from_numpy(cam).float(), out_cam)\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverlay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m           \u001b[49m\u001b[43m.\u001b[49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_overlay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m plt.figure(figsize=(\u001b[32m5\u001b[39m,\u001b[32m5\u001b[39m))\n\u001b[32m    121\u001b[39m plt.imshow(overlay)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/.venv/lib/python3.12/site-packages/torch/serialization.py:964\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    961\u001b[39m     f = os.fspath(f)\n\u001b[32m    963\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m    970\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/.venv/lib/python3.12/site-packages/torch/serialization.py:798\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__exit__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m798\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfile_like\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    799\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.file_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    800\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_stream.close()\n",
      "\u001b[31mRuntimeError\u001b[39m: [enforce fail at inline_container.cc:659] . unexpected pos 832 vs 726"
     ]
    }
   ],
   "source": [
    "# ─── 1) Pick your device ─────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ─── 2) Load the state dict ─────────────────────────────────────────────────\n",
    "state_dict = torch.load(\"reproduceable_densenet.pt\", map_location=\"cpu\")\n",
    "\n",
    "# ─── 3) Instantiate DenseNet121 (no pretrained weights) ────────────────────\n",
    "model = densenet121(pretrained=False)\n",
    "\n",
    "# ─── 4) Patch the first conv to accept 1‐channel input ───────────────────────\n",
    "old_conv = model.features.conv0\n",
    "new_conv = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=old_conv.out_channels,\n",
    "    kernel_size=old_conv.kernel_size,\n",
    "    stride=old_conv.stride,\n",
    "    padding=old_conv.padding,\n",
    "    bias=(old_conv.bias is not None)\n",
    ")\n",
    "with torch.no_grad():\n",
    "    new_conv.weight[:] = old_conv.weight.mean(dim=1, keepdim=True)\n",
    "    if old_conv.bias is not None:\n",
    "        new_conv.bias[:] = old_conv.bias\n",
    "model.features.conv0 = new_conv\n",
    "\n",
    "# ─── 5) Rebuild the classifier to match your num_classes ────────────────────\n",
    "num_classes       = state_dict[\"classifier.weight\"].shape[0]\n",
    "in_feats          = model.classifier.in_features\n",
    "model.classifier  = nn.Linear(in_feats, num_classes)\n",
    "\n",
    "# ─── 6) Load weights & move to device ───────────────────────────────────────\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device).eval()\n",
    "\n",
    "# ─── 7) Load & filter your CSV ───────────────────────────────────────────────\n",
    "df = pd.read_csv(\"best_model_pred_final.csv\")\n",
    "# build your unique_labels list (must match your classifier’s ordering)\n",
    "all_labels    = df[\"true_label\"]\n",
    "unique_labels = sorted(all_labels.unique().tolist())\n",
    "\n",
    "# keep only correct predictions, and exclude certain classes\n",
    "df = df[df.true_label == df.predicted]\n",
    "exclude = {\"ASIAN\", \"HISPANIC/LATINO\"}\n",
    "df = df[~df.true_label.isin(exclude)].reset_index(drop=True)\n",
    "\n",
    "# ─── 8) Set up Grad-CAM hooks ────────────────────────────────────────────────\n",
    "activations = {}\n",
    "gradients   = {}\n",
    "\n",
    "def forward_hook(module, inp, out):\n",
    "    activations[\"feat\"] = out\n",
    "\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    gradients[\"grad\"] = grad_out[0]\n",
    "\n",
    "target_layer = model.features.norm5\n",
    "fh = target_layer.register_forward_hook(forward_hook)\n",
    "bh = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "# ─── 9) Prepare input/output paths ─────────────────────────────────────────\n",
    "test_root  = \"/Users/Kyra_1/Desktop/test_data\"\n",
    "output_dir = \"/Users/Kyra_1/Desktop/local_ADS_data/gradcam_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ─── 10) Loop & generate Grad-CAM, skipping existing outputs ────────────────\n",
    "for _, row in df.iterrows():\n",
    "#for idx, row in df.iloc[203:].iterrows():\n",
    "    fname = os.path.basename(row.dicom_path)\n",
    "    matches = glob.glob(os.path.join(test_root, \"**\", fname), recursive=True)\n",
    "    if not matches:\n",
    "        print(f\"⚠️  File not found: {fname}\")\n",
    "        continue\n",
    "    dicom_path = matches[0]\n",
    "    base, _   = os.path.splitext(fname)\n",
    "\n",
    "    # If all three outputs already exist, skip:\n",
    "    out_cam     = os.path.join(output_dir, f\"{base}_cam.pt\")\n",
    "    out_overlay = os.path.join(output_dir, f\"{base}_overlay.pt\")\n",
    "    out_png     = os.path.join(output_dir, f\"{base}.png\")\n",
    "    if all(os.path.exists(p) for p in (out_cam, out_overlay, out_png)):\n",
    "        print(f\"🔹 Skipping {base}: already done\")\n",
    "        continue\n",
    "\n",
    "    # ---- load & normalize DICOM ----\n",
    "    ds  = pydicom.dcmread(dicom_path, force=True)\n",
    "    arr = ds.pixel_array.astype(\"float32\")\n",
    "    arr_min   = arr.min()\n",
    "    arr_range = np.ptp(arr)        # instead of arr.ptp()\n",
    "\n",
    "    arr = (arr - arr_min) / (arr_range + 1e-6)  \n",
    "    img = Image.fromarray((arr * 255).astype(\"uint8\"))\n",
    "\n",
    "    # ---- forward + backward on true class ----\n",
    "    x       = val_transform(img).unsqueeze(0).to(device)\n",
    "    model.zero_grad()\n",
    "    out     = model(x)\n",
    "    cls_idx = unique_labels.index(row.true_label)\n",
    "    out[0, cls_idx].backward()\n",
    "\n",
    "    # ---- build raw CAM ----\n",
    "    feat  = activations[\"feat\"][0]    # C×h×w\n",
    "    grad  = gradients[\"grad\"][0]      # C×h×w\n",
    "    wts   = grad.mean(dim=(1,2))      # C\n",
    "    cam   = (wts[:,None,None] * feat).sum(dim=0).cpu().detach().numpy()\n",
    "    cam   = np.maximum(cam, 0)\n",
    "    cam   = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "    cam   = cv2.resize(cam, (arr.shape[1], arr.shape[0]),\n",
    "                       interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # ---- build overlay ----\n",
    "    heat    = cv2.applyColorMap((cam*255).astype(\"uint8\"),\n",
    "                                cv2.COLORMAP_JET)[...,::-1] / 255.0\n",
    "    overlay = 0.6 * np.dstack([arr]*3) + 0.4 * heat\n",
    "\n",
    "    # ---- save outputs ----\n",
    "    torch.save(torch.from_numpy(cam).float(), out_cam)\n",
    "    torch.save(torch.from_numpy(overlay)\n",
    "               .permute(2,0,1).float(), out_overlay)\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(out_png, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "# ─── 11) Clean up hooks ─────────────────────────────────────────────────────\n",
    "fh.remove()\n",
    "bh.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de6f0b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kyra_1/Downloads/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/Kyra_1/Downloads/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Skipping 8159799c-7615c0ba-9676dd65-8b0cd6ed-96872c8f: already done\n",
      "🔹 Skipping b9a08a39-c53ad784-99673387-d9140a2f-cbc1dbde: already done\n",
      "🔹 Skipping 163e7408-e7e88bfd-ae448fe2-484a43ec-23ebcf71: already done\n",
      "🔹 Skipping fbc0acfa-ae0bbb10-37a0c81e-bff2aced-678b58b7: already done\n",
      "🔹 Skipping 4c329d77-162e3abb-df1731fc-a0f2354f-4777a58e: already done\n",
      "🔹 Skipping a4ed7ed0-c2305148-b7b09a2e-ec63d023-ef9fd8df: already done\n",
      "🔹 Skipping 6a8f19a4-2030fcda-b0f13ba9-b050a6a1-aa07e72a: already done\n",
      "🔹 Skipping 7ff22806-8d18e0c8-5d2e1bcc-638b22a0-70654bb1: already done\n",
      "🔹 Skipping ed231cb9-58b5647e-672e03e3-d43be791-c485128e: already done\n",
      "🔹 Skipping f24ba3b1-8a4cc77f-23ad8f8c-5c3dca7d-77e2c0da: already done\n",
      "🔹 Skipping 12fd2ed8-5a501563-a86d9388-5ba1a246-2ac9104b: already done\n",
      "🔹 Skipping 5d2545e0-ea3ad600-6a2fa53d-e9336b30-cf8d3179: already done\n",
      "🔹 Skipping bbedc806-4228a38a-e077c922-bcb355a7-f7a6d785: already done\n",
      "🔹 Skipping cb900258-b426b740-fecaaf9d-c43940af-de57c019: already done\n",
      "🔹 Skipping 3cf27c2d-e53f969e-db2660a9-5d8bac0d-aa61dade: already done\n",
      "🔹 Skipping dc8ddef8-8d7d359c-12c0a075-cb23fb80-8e55019a: already done\n",
      "🔹 Skipping 596d6c23-6b89884b-a59f047a-25a7aa7f-34919f90: already done\n",
      "🔹 Skipping d60ba08e-4f4620a4-de4fe1cd-cca05e88-67575eb6: already done\n",
      "🔹 Skipping b6689291-6e6f6d48-e524486c-368664ae-d4105cde: already done\n",
      "🔹 Skipping cdc1eea0-b1eca9b7-d92227fd-b8ad756a-60354f07: already done\n",
      "🔹 Skipping 3dc6222f-f0749104-92394dd8-cb333511-f5a5abd3: already done\n",
      "🔹 Skipping 718dd133-c82f4f6c-fb71b592-d5e257d4-08204b45: already done\n",
      "🔹 Skipping 4c8be7b3-4bdfb53a-5291392a-e9387349-55fd937c: already done\n",
      "🔹 Skipping 6e10391a-9e0a5a2b-dbcc0e88-0cd0bc40-7140181d: already done\n",
      "🔹 Skipping 61ea0ea5-b2b21b9e-36a3056d-0c936cba-73208a6e: already done\n",
      "🔹 Skipping b60c6c0d-9c11585f-98c77706-f9593ca5-565cd308: already done\n",
      "🔹 Skipping 3eb46eea-4913a8ed-e2066eea-1e0954ec-61787f48: already done\n",
      "🔹 Skipping b5b24728-3a780096-e5988cb3-d0717639-2e03159f: already done\n",
      "🔹 Skipping 34feff57-b40bf9db-b10d7ec3-7f9ea9fc-4729552f: already done\n",
      "🔹 Skipping 63123b48-8c5e6d18-1879b704-7ab8511b-58daca84: already done\n",
      "🔹 Skipping a10ddf6c-27ae21b1-6e3d398f-38996661-97190fb2: already done\n",
      "🔹 Skipping 0e6cbec3-9a637b61-386a910d-cb9acb17-3fc360e6: already done\n",
      "🔹 Skipping 1f6ef1b5-6d66ba31-8e6ab2c0-5e2f7af3-8b9167c8: already done\n",
      "🔹 Skipping c47b7ee2-9cc1b4c3-f5a4617e-d71c5469-a2fcbe9e: already done\n",
      "🔹 Skipping 094f66e7-fc7faa70-d5f0b6b5-5a8b82f6-58d284b8: already done\n",
      "🔹 Skipping 0e248a20-f72fb0c4-358b57f0-523c6ffb-193c0d93: already done\n",
      "🔹 Skipping 5bd7288f-3f5b72d4-a232b2bf-5dd71087-d98a9382: already done\n",
      "🔹 Skipping db261736-6f6904d0-f8ec0e3c-aa1298c7-d77189a4: already done\n",
      "🔹 Skipping 0980a3c1-1619b143-6c1eab0a-c9c24f38-7f3b5019: already done\n",
      "🔹 Skipping 4e0ae11d-128f6eb2-7208b911-232a215d-a00aa64b: already done\n",
      "🔹 Skipping ff71e341-eab7d17b-1601438a-8660b305-91aca459: already done\n",
      "🔹 Skipping 247d6722-c9edd24c-4566f541-3c51a14b-421ddb93: already done\n",
      "🔹 Skipping bf664dbd-0ef82b74-98c59299-a2361bc0-7f3e439f: already done\n",
      "🔹 Skipping dbd5e32e-550bcc39-c1cf82c8-a475d285-1fcf2887: already done\n",
      "🔹 Skipping db3d3e1f-bf54356f-97058137-f7012e09-fdd1716f: already done\n",
      "🔹 Skipping 40849251-3763476f-45501279-66669302-d660d29d: already done\n",
      "🔹 Skipping 9d05efbe-b474c031-b94c3bac-081b238e-f816a7e0: already done\n",
      "🔹 Skipping fb100f52-8f256883-630f1f05-8c21c404-2c7552c8: already done\n",
      "🔹 Skipping 434a58ad-d035720e-c1d755b9-215f038c-43ac737b: already done\n",
      "🔹 Skipping 7a9d9bed-499b84ef-282587f0-7beb2404-f5f9f1d6: already done\n",
      "🔹 Skipping 9f7d78ea-3678f7f5-ad9613bc-7e4a779d-b7384021: already done\n",
      "🔹 Skipping e63d615f-d187758e-0c6a290f-7249a615-edababe7: already done\n",
      "🔹 Skipping 52bcf3fd-0019d228-99a44571-ed910c17-549cd103: already done\n",
      "🔹 Skipping ee7287c9-969bff42-1519469b-1e4372f7-f8f86cfe: already done\n",
      "🔹 Skipping d7db2133-ada2333e-2e572dee-874e7484-bf06f86b: already done\n",
      "🔹 Skipping a9e5c834-0172699b-42f007d0-9ae4047b-b961607e: already done\n",
      "🔹 Skipping cea7df4d-273f1e49-5c8f512c-8641a418-cd6448db: already done\n",
      "🔹 Skipping 05208944-8e9ce46d-90f6f03d-f687c8e5-de0044d8: already done\n",
      "🔹 Skipping 4ce273d7-4dfdf94f-d1dfcfe8-c648efcd-29685a0f: already done\n",
      "🔹 Skipping b1eef87b-116887fe-4115a984-9bd86f2d-4fbbdb73: already done\n",
      "🔹 Skipping cd4ac979-ce417d3e-37b3ee82-e1e3deac-b6a91fe5: already done\n",
      "🔹 Skipping bb78708f-3aff2b4c-a76a6f27-8e3e5ce2-ab51e5c3: already done\n",
      "🔹 Skipping a83cbc15-9f45869b-3a99d499-07a3276d-4a96b453: already done\n",
      "🔹 Skipping b9b552e6-4e319be2-4d1102d1-c89b2ff8-d21f0e82: already done\n",
      "🔹 Skipping 520dc282-d5ce8b7d-ef0e1164-8f46068f-12c3117e: already done\n",
      "🔹 Skipping a3692227-7756b781-f9053e7a-563a314a-8578964d: already done\n",
      "🔹 Skipping be7a6119-ada34607-44a15883-f2dc1723-e27ace37: already done\n",
      "🔹 Skipping 1fda5b35-9bcacfc6-759a1d10-8a51bc06-dc8f93aa: already done\n",
      "🔹 Skipping 4483cc52-27eb44e8-3b4d1b59-1bd4039c-f6f29423: already done\n",
      "🔹 Skipping ddc47471-94c7b59c-b7dcd54a-0ecf3cfd-339563ee: already done\n",
      "🔹 Skipping 937f4f8f-5101e609-1936e8db-a3fa7358-0ed5cc0d: already done\n",
      "🔹 Skipping f9ef10ca-9d14eb70-e87de9eb-a4860177-1ee90f83: already done\n",
      "🔹 Skipping 283b9c5c-97b8852b-c8b7c7f5-abc75146-1a9e12c3: already done\n",
      "🔹 Skipping 7986cd76-7be63b70-35279266-4cf21f5d-6a7bc690: already done\n",
      "🔹 Skipping 511cd370-46c0aa25-76d25ee5-eebd8940-664e6636: already done\n",
      "🔹 Skipping 90dabf0d-15666735-160248f8-c96dfec0-bf506a68: already done\n",
      "🔹 Skipping 60a20822-1dcc4678-f567982e-5444978a-28daa8e4: already done\n",
      "🔹 Skipping 60d2bbd4-07a7364d-c008736f-44304ecc-dd17406f: already done\n",
      "🔹 Skipping 2738bd5e-598ade3a-53795582-7de3c225-a307b10a: already done\n",
      "🔹 Skipping 2d4114ed-d8090258-0f09f0a0-31acaa18-ba572c23: already done\n",
      "🔹 Skipping 5d85b0f7-d39c16f9-cd63f824-c58dc193-af708c90: already done\n",
      "🔹 Skipping 4d41b552-b5add68b-27f6549e-dcca2d20-ceb21ff1: already done\n",
      "🔹 Skipping 731c98a7-e9284453-6ec229e3-4be33583-468b4ac5: already done\n",
      "🔹 Skipping 7107d171-af91feac-c08a62e2-869c3044-6b9379b2: already done\n",
      "🔹 Skipping b2ddebcd-1e1c6d24-f9547478-6e70a16d-afc41c7d: already done\n",
      "🔹 Skipping 024f2a01-7903ec70-0d926a8e-7dcbbabf-4b19fe63: already done\n",
      "🔹 Skipping 9687990d-d29a073f-4e22abfb-e52a45b6-dad94aac: already done\n",
      "🔹 Skipping f721b4f6-2806f0b2-866a31ed-9c4ce4e3-0b389489: already done\n",
      "🔹 Skipping b7fc3517-dd72ab6b-fe8826e7-93b3186a-cbc6f8ec: already done\n",
      "🔹 Skipping a523e86f-70f6f30e-a47fd4c5-25431361-7a74b594: already done\n",
      "🔹 Skipping 98920f09-4fa61310-e2d5abca-e8c92bb0-a792d4bc: already done\n",
      "🔹 Skipping 465c8878-73f5aa87-9eaead65-04c4dad1-679ac908: already done\n",
      "🔹 Skipping 1671b6ed-d2406106-013f87c7-eb456610-6d3f21e4: already done\n",
      "🔹 Skipping 58480434-e6739b7a-5e224439-682ce560-c6860fae: already done\n",
      "🔹 Skipping 0ba3c229-bd12ece4-a36dedf9-2b0bc5d2-399705ee: already done\n",
      "🔹 Skipping b8851a9f-bd9f2719-bff17c13-47eb6a6b-3be30e86: already done\n",
      "🔹 Skipping 0316aaac-7c4e3721-39464841-c0322f51-07f349ab: already done\n",
      "🔹 Skipping 6d9466e0-c47992a5-cff22f3d-7ba8ce7e-5575f4a4: already done\n",
      "🔹 Skipping 8a616cd4-6a19a903-58510951-489b9c9a-2ead3ee3: already done\n",
      "🔹 Skipping dca16a92-ab15b8fc-18c88378-329b42d7-f2c8b202: already done\n",
      "🔹 Skipping aab76df3-54492565-bc7d5755-60844db6-e10feab9: already done\n",
      "🔹 Skipping ebc40899-d487e83a-974c9d47-975a0a7a-dc2326d6: already done\n",
      "🔹 Skipping 3dd1aca6-84abdea7-788a8d1d-497fdea1-bf49f105: already done\n",
      "🔹 Skipping 8d98fa61-b9cdd74a-600239e7-073d7083-077373d9: already done\n",
      "🔹 Skipping 3cb0acc6-d9cecf35-60bc5214-eba40980-61ac3699: already done\n",
      "🔹 Skipping e79345f2-f5d22a13-9c0115e7-ba64ed87-594dd695: already done\n",
      "🔹 Skipping 00e3be41-71f375ee-f03e856f-53e98273-473606c8: already done\n",
      "🔹 Skipping 74935855-0245c3d6-6ea39c0f-ac8f3bbc-cbe1c890: already done\n",
      "🔹 Skipping c82c4cc9-0da567f2-5b9a739c-7622fa90-9262607f: already done\n",
      "🔹 Skipping fed2fc83-47e88a27-a73c6620-5a5cb4a9-a029623d: already done\n",
      "🔹 Skipping 7b41fa3c-fc44b38c-86311fed-b4a4a0c5-feeb4e4b: already done\n",
      "🔹 Skipping 2ac56140-76444511-fb743ba7-3f5f0659-b937f9ef: already done\n",
      "🔹 Skipping a2af85ca-11111670-1b9b6afb-c21dfac6-86ba33e7: already done\n",
      "🔹 Skipping 1709efb0-bc4fcaf1-8e54f22d-6281c041-57d82b89: already done\n",
      "🔹 Skipping b3a95065-4404aa8f-1d2b8735-ce1e35a9-624bd5b4: already done\n",
      "🔹 Skipping 9c7737c0-c77c7ff4-eb6d8bcd-e7d1adea-4bcd16bc: already done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kyra_1/Downloads/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1842: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.00015067805361468345..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.028739003464579582..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [9.641652286518365e-05..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.003409678116440773..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.0000000238418578].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Skipping 07e9a0b4-52559819-ede26703-11403ead-a9b761d5: already done\n",
      "🔹 Skipping 5d93739f-badcdac7-b7414fdb-8db69418-9838f396: already done\n",
      "🔹 Skipping 7776726a-5d5ceb10-22fa9917-3b7d11de-d413472a: already done\n",
      "🔹 Skipping 336f2d98-81dbf659-f12c3003-665a59e4-7c040148: already done\n",
      "🔹 Skipping cf8e40e4-13142780-e760eaf4-54a31990-8b748ee4: already done\n",
      "🔹 Skipping 843946d3-fd44acc6-6a826d5c-c7242336-cf599b15: already done\n",
      "🔹 Skipping 321bf6a2-75f7bbe3-b7515fac-a892f6cb-a3c07862: already done\n",
      "🔹 Skipping 58055944-a4cda095-067c7c2e-8d6a4214-3c50f0c2: already done\n",
      "🔹 Skipping 8a3efe56-73f935de-bfce35d7-d056e503-48b984ec: already done\n",
      "🔹 Skipping 36b93225-8b7956ca-80a09685-70e55196-39dc2a14: already done\n",
      "🔹 Skipping 54823b86-6b79c371-fa400bea-ff0dfa32-2ff9a43a: already done\n",
      "🔹 Skipping d2c06203-af9fc488-12a138f1-9a6b4ece-ae383690: already done\n",
      "🔹 Skipping 4e16d481-6e8f54bb-05790943-e19ccf55-cd17dd06: already done\n",
      "🔹 Skipping 608e7747-d0e18df3-0293e862-f05411be-c027d53b: already done\n",
      "🔹 Skipping e52db541-1d0bfb96-2ed42917-03270a7f-20881089: already done\n",
      "🔹 Skipping 6ae90aa5-ff1092b3-7bcfff6f-bb7e80c5-96ded19a: already done\n",
      "🔹 Skipping adbf7304-4fb6b60d-9f0edb58-380824c6-8aadc787: already done\n",
      "🔹 Skipping 9fcd01ee-d83d9bba-5692b6a5-572b320c-50bedf5c: already done\n",
      "🔹 Skipping 7fddb5cc-c82491f9-6b4585b3-2845640d-4ad37134: already done\n",
      "🔹 Skipping ae41aacc-e99e1945-d4e8c4a8-3efb3566-62ed861b: already done\n",
      "🔹 Skipping c31b9515-d88937d7-8dd7e2a6-4e780765-c91b0b25: already done\n",
      "🔹 Skipping 35ee2f86-bd962a3c-bc86a042-a644bfbe-46293d4b: already done\n",
      "🔹 Skipping 91e01580-947a16cb-13b46acd-c1383806-a1c1319f: already done\n",
      "🔹 Skipping 1945ab42-0276b8d5-39a0f370-0e445669-5ff43c37: already done\n",
      "🔹 Skipping 6e0365b9-c1a8d0aa-63ce8e73-5c649920-027cc938: already done\n",
      "🔹 Skipping b890ce01-a188713e-34f19d04-d30eb75f-2610450a: already done\n",
      "🔹 Skipping b90d1c05-adc906da-e0aa3416-d12cf1cd-893ec1ab: already done\n",
      "🔹 Skipping 325acc35-43945dc6-f6427101-80d68765-c35672e3: already done\n",
      "🔹 Skipping 3d33231d-4397633d-b6393745-01d7c655-d85cc992: already done\n",
      "🔹 Skipping f2f3990b-27a6d6f2-d1478a10-c9e022dd-f73aafec: already done\n",
      "🔹 Skipping c97436d8-324b675b-6ebc8e7b-da73ec69-304ef4fc: already done\n",
      "🔹 Skipping d0a99c36-10b174f6-aa5e4a94-599cf090-c91c273d: already done\n",
      "🔹 Skipping dced812b-b124c5e9-f4ad0877-23d37c60-1c0c641e: already done\n",
      "🔹 Skipping f371535c-acb691b9-6bff3cf9-2abd827b-354a1530: already done\n",
      "🔹 Skipping 1e0b0c73-71a2e5a1-ee7a49c1-c6d1216d-9bcfdfa3: already done\n",
      "🔹 Skipping 8dc08730-b5d3792e-6599eb9a-74d248f0-f0dac3a3: already done\n",
      "🔹 Skipping 77fadf76-d8c295e5-ccd7576a-71d91f57-b3c9cee3: already done\n",
      "🔹 Skipping cf609e2e-b8b17d6f-e85d373f-4ab0f455-feb993cc: already done\n",
      "🔹 Skipping 4bba6f01-16facefc-14df4f77-95aed48c-ecbcb443: already done\n",
      "🔹 Skipping c2bf48f8-7fd05363-817fe042-0bd2aa59-79dcd704: already done\n",
      "🔹 Skipping 129eaf83-e2f46e54-0588778f-5095b98e-f88f8101: already done\n",
      "🔹 Skipping 2db9e390-f7c88f0f-afb3683a-0eb7b1c0-902dcfed: already done\n",
      "🔹 Skipping 18f70ebb-f1db8ea6-e4df2162-49032383-8961b14e: already done\n",
      "🔹 Skipping 45bcac29-af20df39-9d9807d7-896e7261-aab0187d: already done\n",
      "🔹 Skipping b6133957-0c5a65b9-08a1d086-2442edfd-66db92a0: already done\n",
      "🔹 Skipping e145afa8-dbe3bab5-9d42ead6-f2706508-7a81c195: already done\n",
      "🔹 Skipping 018a644b-b08edb22-5ef8f2b9-31ebd837-eb987702: already done\n",
      "🔹 Skipping 682f985d-ba79ecfc-9c9b847a-d21df76f-8cf1cbd3: already done\n",
      "🔹 Skipping ab03370f-49244a55-00b0cda2-1dd8c735-39b1529a: already done\n",
      "🔹 Skipping d6976b79-73a96d63-a498a7f7-c081d0dc-b1a8e757: already done\n",
      "🔹 Skipping 50364eef-e3be6d73-26daca3e-101ddd48-744ce688: already done\n",
      "🔹 Skipping 6850d485-a4d126fe-fb32e234-1a485e31-ea9b09f0: already done\n",
      "🔹 Skipping e641ee9e-55996591-f5b35954-85b77d04-5abba534: already done\n",
      "🔹 Skipping 9c9055d4-fe0983a4-74eda1df-b215e964-f24cc6fb: already done\n",
      "🔹 Skipping cac722bc-64599899-23a9ff02-e19fbd02-a5fe2c04: already done\n",
      "🔹 Skipping 3dcd4f36-5d20f672-2a08709c-2580bb8f-afaef29d: already done\n",
      "🔹 Skipping 486e1cfc-2e5a992b-70ebb547-67aaa702-d9ed0cd5: already done\n",
      "🔹 Skipping 8d6c45c2-e27c4a0f-f89c8636-e6e3b232-c73032a8: already done\n",
      "🔹 Skipping 9c148b24-e077b0ee-64a04995-4a65798c-5e05451c: already done\n",
      "🔹 Skipping a19d6995-90cf58c9-07bda657-74fc03b4-1bd5b969: already done\n",
      "🔹 Skipping 3d80726c-1beb201d-bc36fe7b-a433f51f-dd002fb5: already done\n",
      "🔹 Skipping ab5797ed-18ea3dcb-57f58b7c-e1838baa-4030a559: already done\n",
      "🔹 Skipping 9c11d715-41902fd3-9fddce18-791b499d-22619182: already done\n",
      "🔹 Skipping 32da1114-e1c5624d-c5d5aebe-0ba48a6b-640744c0: already done\n",
      "🔹 Skipping a34b1c2a-64c4e723-548abdd0-a3c96bad-2c1cfd2c: already done\n",
      "🔹 Skipping 256c7977-f87398cb-f3f664ad-5add1cf9-c8c4fb18: already done\n",
      "🔹 Skipping 5992b97e-62a27a0c-b39a1712-8a18d633-6e81f393: already done\n",
      "🔹 Skipping 6fb2656b-4a2d473d-145779f0-22bd2c5d-0df2def6: already done\n",
      "🔹 Skipping 6f7c3104-73869050-06dd68f4-b1af81b4-8b042133: already done\n",
      "🔹 Skipping c530b46c-3be7e3c6-28f91990-b9152ec4-2f61ea52: already done\n",
      "🔹 Skipping 0ac242fc-5a45e0a3-9f749528-cecd3ef5-389d9eeb: already done\n",
      "🔹 Skipping 7dfef2d9-f5a8922c-2883fc6f-0d50b6ee-f98a2211: already done\n",
      "🔹 Skipping 0c76db15-31603629-ab7feb12-4a3fb9ab-f0fc3113: already done\n",
      "🔹 Skipping c855c647-b601bf86-88a55216-db98b9f9-7d6451b6: already done\n",
      "🔹 Skipping 05bf45ce-a5794417-ec937e4a-4df0af8b-06b4dbf7: already done\n",
      "🔹 Skipping 9c86b74b-dc06c84d-9d7f4326-ad5f63cd-095534ad: already done\n",
      "🔹 Skipping a99e0786-a5e51b44-5492772b-3ba1f4fc-3a94bf01: already done\n",
      "🔹 Skipping b7a5b337-1e84d09e-cfa35ce3-ac8cc808-b13314b1: already done\n",
      "🔹 Skipping 5c06fefa-f2e3f331-fc3d7ffb-ec307c59-cd760060: already done\n",
      "🔹 Skipping e1963b14-a6012c8b-69adbf07-719d8c13-ffa7b314: already done\n",
      "🔹 Skipping 4a1850ea-702accff-69e06497-b51a7963-3399be8e: already done\n",
      "🔹 Skipping c051587a-78420e8c-52a025f5-d0175812-4adc22df: already done\n",
      "🔹 Skipping 0ef86855-1425e2a3-010ac038-e2025928-776d39d9: already done\n",
      "🔹 Skipping 55997684-7424e92f-644a4d6e-4a1914c2-21df3ea1: already done\n",
      "🔹 Skipping 7fcec41d-c01e20e4-bf52c374-9b11e390-d62cd084: already done\n",
      "🔹 Skipping b61d6ea7-86337e7b-a45f71ca-ab8729de-3ed7c515: already done\n",
      "🔹 Skipping 309a05df-701f14be-17150102-a16e9a47-66f6a0f9: already done\n",
      "🔹 Skipping fe76dbf7-bf6e5742-9823080e-313730e6-3465eb2e: already done\n",
      "🔹 Skipping 470fc564-5d3e1517-d44033c6-a21e72ed-492c07f2: already done\n",
      "🔹 Skipping 1843fb57-c53b5ad7-de39ad5a-3701dd61-91114279: already done\n",
      "🔹 Skipping ef6888ab-f38a23db-a60db668-0811ad2b-a669bf07: already done\n",
      "🔹 Skipping 04f19f53-ef0e588f-a480bcee-8e032339-ac74bbd6: already done\n",
      "🔹 Skipping e85aa26a-1016a3af-c056c39b-f18fc709-4e24e795: already done\n",
      "🔹 Skipping dfd00ea2-22238bc7-944a82fb-061f6c5c-7a8e2b43: already done\n",
      "🔹 Skipping e369a6a1-094a1813-75ce5fec-ca5862b0-07ce2b71: already done\n",
      "🔹 Skipping 419d19c4-92d1412c-8031836e-9cb93e89-8467b937: already done\n",
      "🔹 Skipping f6b2ad9c-e0c1f977-9c2c155f-6bd5bc00-9815fa72: already done\n",
      "🔹 Skipping 16fdc6c0-001f5596-b13a20a0-6344bef8-9bf1946c: already done\n",
      "🔹 Skipping 8e4d9346-c4b1a74d-bca90c2a-b398dbd9-16f05bb5: already done\n",
      "🔹 Skipping 9e29d840-659f2dc0-5853f6e1-d558798d-6ede04ab: already done\n",
      "🔹 Skipping caec1bd2-623ffd33-0336db31-6d11c0a3-05900787: already done\n",
      "🔹 Skipping 0c822cc5-182f73e2-6d43ef0f-3fc169e4-38e2a9e4: already done\n",
      "🔹 Skipping 102e7590-77167cfc-148b5422-710cdf1a-9dfe2eba: already done\n",
      "🔹 Skipping 01bf2870-1d1599ea-e8b67d2e-1df6f4f3-309c855d: already done\n",
      "🔹 Skipping a86db3b4-b0d9e006-d3aa8dbc-25d99174-d1cadbb7: already done\n",
      "🔹 Skipping b79b28d6-2b8681cc-9a182b09-97cf3c1a-70611b64: already done\n",
      "🔹 Skipping e1f61dab-afa7623f-ce2b8138-7e75b86c-b1149361: already done\n",
      "🔹 Skipping 2f7ee079-3757a2d0-2b243bf2-69be499a-0ae23c97: already done\n",
      "🔹 Skipping e593fd9e-f589d466-63ba7150-cbc8e015-9e345a80: already done\n",
      "🔹 Skipping 3f27379b-48640193-af7495ec-eebcfb39-44fad046: already done\n",
      "🔹 Skipping b4074f90-c91a50f0-fc4548f4-9564ac73-7b054f91: already done\n",
      "🔹 Skipping 0e538813-ea9a441b-42f25edb-5614343a-a9e54820: already done\n",
      "🔹 Skipping 5e9307b4-4e08ccdb-45f8f093-b44ec973-2954f880: already done\n",
      "🔹 Skipping 632bef7f-0690b08a-c675607e-0736afed-e17d72e7: already done\n",
      "🔹 Skipping 6a5271f0-64d70117-d9f8aba4-49e09802-7d576515: already done\n",
      "🔹 Skipping 3c83866a-a7b52aa2-d26a0dd3-c8c14378-f4380988: already done\n",
      "🔹 Skipping 918caf2f-d0279def-812ca078-0d8adbf0-9721fc59: already done\n",
      "🔹 Skipping 53f8efa9-4eab3bd0-53183a41-b74c0467-4e74672a: already done\n",
      "🔹 Skipping 7ba70acd-c543c594-6a4b40fe-43b724b0-ec0090a5: already done\n",
      "🔹 Skipping b6e7f72f-86745590-4fe1cc18-c9840a74-c7da3a56: already done\n",
      "🔹 Skipping ee5c35ee-ea7d2632-183ad8cd-64834c6c-6cc288c5: already done\n",
      "🔹 Skipping 5edb8cbb-53428475-59c96867-e3224515-b882268e: already done\n",
      "🔹 Skipping 767da013-3bd419d1-b8898729-4e46ac78-41ce9466: already done\n",
      "🔹 Skipping 039d92f8-87610657-dee2ebd6-8f4367a6-22e41865: already done\n",
      "🔹 Skipping d42d35be-7a30b1e4-dce4b516-713df37d-936ae449: already done\n",
      "🔹 Skipping 5aa7678f-dda35f39-5ba47a77-c5f7078b-b9d4cc74: already done\n",
      "🔹 Skipping e91e10d5-f3636871-8f556b78-0c92b3ba-a8a13d34: already done\n",
      "🔹 Skipping 205d5d26-40da6d4f-35469a7a-47c9bc26-3b4e35f8: already done\n",
      "🔹 Skipping a4f8553d-4dff2fb7-1cd2b9ed-2de624a5-9cba226a: already done\n",
      "🔹 Skipping 1cadf9b7-3a80f170-55b3b461-29c4137c-9d2cf236: already done\n",
      "🔹 Skipping 355eb0b0-6a3859ae-90e9e251-1fd6830b-4df193af: already done\n",
      "🔹 Skipping ef826648-2bd74947-6178434a-6b734fc1-5ac2b0cc: already done\n",
      "🔹 Skipping 1ded9e57-2ae4598b-8820e166-c3d3c236-6ec5d83a: already done\n",
      "🔹 Skipping 792116fd-954c3972-eed4af7d-71ea527b-23c6f2df: already done\n",
      "🔹 Skipping ec6b52a2-253cc596-058a8b1b-c09e8e8a-2d2dd989: already done\n",
      "🔹 Skipping 5936f73f-779ecbe0-eb9643ce-03967181-4b17c57c: already done\n",
      "🔹 Skipping eab9e790-eff9264a-dccde0a2-7e665ab7-ce9263be: already done\n",
      "🔹 Skipping 2215d34c-f14623b4-5d3bc402-0a69319a-673327a0: already done\n",
      "🔹 Skipping d3491717-eb966271-c1ac828c-293bf7ce-96c294f2: already done\n",
      "🔹 Skipping f5c48c61-d59a1899-f625676c-6991e3de-3da67d46: already done\n",
      "🔹 Skipping f9352023-b463a2f9-7cd6c601-f3ecdde3-77af29e5: already done\n",
      "🔹 Skipping 7fabfc78-6c43e025-28913fbb-ad2c9f4a-78b18bef: already done\n",
      "🔹 Skipping dafefc07-7b63a525-8dfbd126-765fa926-5dea1e15: already done\n",
      "🔹 Skipping 21896684-6c844f9f-aa163351-e2584e59-e54305f6: already done\n",
      "🔹 Skipping 9df6ddc6-ae7eab1d-e5e0085a-9998d4ab-8690b5cd: already done\n",
      "🔹 Skipping c2a185ce-e9bd7534-b2d0efae-a56df102-870b4db1: already done\n",
      "🔹 Skipping b999eb5c-18caaa03-8d197788-3ed53a62-1d618382: already done\n",
      "🔹 Skipping cf7e09f5-88f19799-c60d49f7-4026ffce-1a8b4a5e: already done\n",
      "🔹 Skipping d8730cbf-5a543087-2160793f-d06879ea-1f0724c2: already done\n",
      "🔹 Skipping 0554c40d-4d53c594-51763320-5e178b94-94206654: already done\n",
      "🔹 Skipping 07e65271-82c338e6-d9aec05d-735be081-17705b18: already done\n",
      "🔹 Skipping 239c00ac-c96160c5-6984c753-2cfc9af3-529d2377: already done\n",
      "🔹 Skipping b6b4cc60-85077799-40e502cf-d5e67c4c-0c0b099d: already done\n",
      "🔹 Skipping c709bced-79fc240a-387a03bc-d6f85ba4-52bee402: already done\n",
      "🔹 Skipping c925886b-cf51522a-26ed8ad0-834344ca-4c51d743: already done\n",
      "🔹 Skipping 6e4af792-52bc9013-6c17a759-2d0f7229-b00ca220: already done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import densenet121\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─── 1) Pick your device ─────────────────────────────────────────────────────\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ─── 2) Load the state dict ─────────────────────────────────────────────────\n",
    "state_dict = torch.load(\"reproduceable_densenet.pt\", map_location=\"cpu\")\n",
    "\n",
    "# ─── 3) Instantiate DenseNet121 (no pretrained weights) ────────────────────\n",
    "model = densenet121(pretrained=False)\n",
    "\n",
    "# ─── 4) Patch the first conv to accept 1‐channel input ───────────────────────\n",
    "old_conv = model.features.conv0\n",
    "new_conv = nn.Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=old_conv.out_channels,\n",
    "    kernel_size=old_conv.kernel_size,\n",
    "    stride=old_conv.stride,\n",
    "    padding=old_conv.padding,\n",
    "    bias=(old_conv.bias is not None)\n",
    ")\n",
    "with torch.no_grad():\n",
    "    new_conv.weight[:] = old_conv.weight.mean(dim=1, keepdim=True)\n",
    "    if old_conv.bias is not None:\n",
    "        new_conv.bias[:] = old_conv.bias\n",
    "model.features.conv0 = new_conv\n",
    "\n",
    "# ─── 5) Rebuild the classifier to match your num_classes ────────────────────\n",
    "num_classes      = state_dict[\"classifier.weight\"].shape[0]\n",
    "in_feats         = model.classifier.in_features\n",
    "model.classifier = nn.Linear(in_feats, num_classes)\n",
    "\n",
    "# ─── 6) Load weights & move to device ───────────────────────────────────────\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to(device).eval()\n",
    "\n",
    "# ─── 7) Load & filter your CSV ───────────────────────────────────────────────\n",
    "df = pd.read_csv(\"best_model_pred_final.csv\")\n",
    "all_labels    = df[\"true_label\"]\n",
    "unique_labels = sorted(all_labels.unique().tolist())\n",
    "\n",
    "df = df[df.true_label == df.predicted]\n",
    "exclude = {\"ASIAN\", \"HISPANIC/LATINO\"}\n",
    "df = df[~df.true_label.isin(exclude)].reset_index(drop=True)\n",
    "\n",
    "# ─── 8) Set up Grad‐CAM hooks ────────────────────────────────────────────────\n",
    "activations = {}\n",
    "gradients   = {}\n",
    "\n",
    "def forward_hook(module, inp, out):\n",
    "    activations[\"feat\"] = out\n",
    "\n",
    "def backward_hook(module, grad_in, grad_out):\n",
    "    gradients[\"grad\"] = grad_out[0]\n",
    "\n",
    "target_layer = model.features.norm5\n",
    "fh = target_layer.register_forward_hook(forward_hook)\n",
    "bh = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "# ─── 9) Prepare input/output paths on Extra Storage ─────────────────────────\n",
    "DRIVE_ROOT = \"/Volumes/Extra Storage\"\n",
    "test_root  = os.path.join(DRIVE_ROOT, \"test_data\")\n",
    "output_dir = os.path.join(DRIVE_ROOT, \"local_ADS_data\", \"gradcam_results\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ─── 10) Loop & generate Grad‐CAM, skipping existing outputs ────────────────\n",
    "for idx, row in df.iterrows():\n",
    "    fname = os.path.basename(row[\"dicom_path\"])  # or row[\"full_path\"] if that’s your column\n",
    "    matches = glob.glob(os.path.join(test_root, \"**\", fname), recursive=True)\n",
    "    if not matches:\n",
    "        print(f\"⚠️  File not found: {fname}\")\n",
    "        continue\n",
    "    dicom_path = matches[0]\n",
    "    base, _    = os.path.splitext(fname)\n",
    "\n",
    "    out_cam     = os.path.join(output_dir, f\"{base}_cam.pt\")\n",
    "    out_overlay = os.path.join(output_dir, f\"{base}_overlay.pt\")\n",
    "    out_png     = os.path.join(output_dir, f\"{base}.png\")\n",
    "    if all(os.path.exists(p) for p in (out_cam, out_overlay, out_png)):\n",
    "        print(f\"🔹 Skipping {base}: already done\")\n",
    "        continue\n",
    "\n",
    "    # ---- load & normalize DICOM ----\n",
    "    ds        = pydicom.dcmread(dicom_path, force=True)\n",
    "    arr       = ds.pixel_array.astype(\"float32\")\n",
    "    arr_min   = arr.min()\n",
    "    arr_range = np.ptp(arr)\n",
    "    arr       = (arr - arr_min) / (arr_range + 1e-6)\n",
    "    img       = Image.fromarray((arr * 255).astype(\"uint8\"))\n",
    "\n",
    "    # ---- forward + backward on true class ----\n",
    "    x       = val_transform(img).unsqueeze(0).to(device)\n",
    "    model.zero_grad()\n",
    "    out     = model(x)\n",
    "    cls_idx = unique_labels.index(row.true_label)\n",
    "    out[0, cls_idx].backward()\n",
    "\n",
    "    # ---- build raw CAM ----\n",
    "    feat = activations[\"feat\"][0]    # C×H×W\n",
    "    grad = gradients[\"grad\"][0]      # C×H×W\n",
    "    wts  = grad.mean(dim=(1,2))      # C\n",
    "    cam  = (wts[:,None,None] * feat).sum(dim=0).cpu().detach().numpy()\n",
    "    cam  = np.maximum(cam, 0)\n",
    "    cam  = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "    cam  = cv2.resize(cam, (arr.shape[1], arr.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # ---- build overlay ----\n",
    "    heat    = cv2.applyColorMap((cam*255).astype(\"uint8\"),\n",
    "                                cv2.COLORMAP_JET)[...,::-1] / 255.0\n",
    "    overlay = 0.6 * np.dstack([arr]*3) + 0.4 * heat\n",
    "\n",
    "    # ---- save outputs ----\n",
    "    torch.save(torch.from_numpy(cam).float(),    out_cam)\n",
    "    torch.save(torch.from_numpy(overlay)\n",
    "               .permute(2,0,1).float(),        out_overlay)\n",
    "\n",
    "    # ---- dump a quick PNG ----\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(out_png, bbox_inches=\"tight\", pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "# ─── 11) Clean up hooks ─────────────────────────────────────────────────────\n",
    "fh.remove()\n",
    "bh.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf65c9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
